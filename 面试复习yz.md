# 面经整理

如何介绍一个东西：这东西是干什么的，里面的一些基本概念，好处在哪，如何实现，应用场景。

## 1.http和https的区别



对称：AES，非堆成：RSA（**大数互质和欧拉函数**），hash：SHA（加盐，生成一个64位的签名）， MD5

Http是超文本传输协议，是基于TCP连接的一种无状态协议，这里的无状态是指http协议不会记录用户的数据，传输，建立连接都是独立的过程，然后传输的过程没有经过加密，都是明文传输。

具体传输过程就是客户端建立tcp连接，然后发送一个请求给服务端，格式为：一个URL，协议版本号，然后就是请求头和请求体的信息

服务端接收到请求之后，执行相应的逻辑，然后返回一个response。

优点：简单，没有过多的操作，数据传输快。

缺点：因为没有加密，以及没有身份认证，所以说会存在：数据泄露，数据被篡改，以及访问被重定向到错误的系统的问题，所以说会存在身份认证的问题。

https的话就在http的基础上添加了一层ssl/tcl协议，具体就是为了解决前面http说的三个可能存在的问题，身份认证，数据泄露和数据完整性问题。

然后这也对应了https中存在的三种加密算法：非对称加密，对称加密和散列加密，证书。

1. 客户端发起一个https的请求，这里面会包含版本号，我支持的加密套件，c，压缩套件。（明文）
2. 服务接收到客户端的请求之后，会发送两个报文，第一个报文就会去在客户端提供的上**加密套件**以及**压缩算法**，并且生成一个随机数p返回给客户端。
3. 第二个报文还会发送自己的证书信息
   1. 证书信息包括：（使用最高权威机构的私钥加密）
      1. **服务器域名**
      2. **服务器的公钥**
      3. **权威机构的信息**
      4. **经过CA私钥签名之后的证书内容（先hash算法计算出上述内容的摘要，然后使用服务器的私钥加密）**
4. 此时如果需要双端做证书交换的话，客户端也会发送自己的证书给服务端。客户端在接收到服务端发送的信息之后，会验证证书信息（TLS），**主要验证域名是否相同，根据证书链来验证证书的有效性，证书是否过期等等**。
5. 验证完毕之后，客户端会根据c和p，确定一个特定的随机数m表示**会话密钥**，然后通过**证书公钥**加密，发送给服务端。**另外还会使用确定好的散列算法，求出和服务端在此次连接过程中收到的所有信息的摘要，以及根据c，p和随机数m确定的专属密钥来加密接受到的信息以及信息的摘要**，发送给服务端。
6. 服务端首先根据自己的私钥解密发来的密钥信息，提取出会话密钥，计算出临时公钥，然后开始解析信息并且验证信息是否完整。
7. **如果完整，服务端也将自己的接收到的信息加密，然后用专属公钥加密，发送给客户端**。

整个过程下来就保证了身份认证（证书），数据加密（专属密钥），数据完整性（hash算法）。

为什么传输要用对称而不是非对称：非对称慢，对称加密比较快。

对称为什么要生成新的密钥：方便服务端一对多。



`func getMaxMinNum(n int, numbers []int) {
   n--                    //保证最后的值是小于n的值，防止最后匹配的数字为n
   str := strconv.Itoa(n) //将n变成字符串，方便从左往右遍历数字
   var num int
   res := make([]int, 0) //创建一个结果数组，存储数字集合，类似于list 你的vector
   for i := 0; i < len(str); i++ {
      num = int(str[i] - '0')             //获取第i位的数字
      index := binarySearch(numbers, num) //查找小于等于该数字的最大值在number中的下标
      //根据index来判断
      if index == -1 { //说明不存在比其小或者等于的值，直接回溯，说明要前面已经选择的某一位数字缩小
         index1 := i - 1 //从后往前找第一个能够缩小的值，因为我们要取最大值，所以肯定是希望低位缩小一丢丢
         for index1 >= 0 {// 
            temp := binarySearch(numbers, res[index1])
            if temp != -1 { //找到了一个可以缩小的值，说明第index1位的数字可以缩小
               //添加,下面的步骤其实就是添加这个数字辣！！！！！！！
               res = res[:index1]
               res = append(res, numbers[temp]) //因为这里index1取了一个比之前的小的值，所以index1后续的所有值都可以替换为number的最大值
               for j := index1 + 1; j < len(str); j++ {
                  res = append(res, numbers[len(numbers)-1]) //添加number中的最大值
               }
               break//退出辣！！！！！
            }
            index1--
         }
         if index1 >= 0 {//这里就是判断是否找到最小的值，如果这个index1<0 那么说明是因为循环条件不满足的才退出的，不是因为上面的break
            break
         }
         //到这里发现不存在一个从后往前能缩小的值，那么只能将数字替换为比n的位数小一位的最大值，比如原来n是5位，那么我就取一个4位的数字辣！！！1
         res = res[:0]
         for j :=1; j < len(str); j++ {
            res = append(res, numbers[len(numbers)-1])
         }
         break
      } else {
         if num == numbers[index] { //存在一份相等的值，添加，往后走
            res = append(res, numbers[index]) //添加
         } else { //小于，那么后面的所有数字都可以取最大的值
            res = append(res, numbers[index]) //添加
            for j := i + 1; j < len(str); j++ {
               res = append(res, numbers[len(numbers)-1]) //添加number中的最大值
            }
            break
         }
      }
   }
   fmt.Println(res)
}`







`public void getMaxMinNum(int n , int [] numbers ) {
    n--;                //保证最后的值是小于n的值，防止最后匹配的数字为n
    String str=""+n; //将n变成字符串，方便从左往右遍历数字
    int num=0;
    Arrays.sort(numbers);
    List<Integer> res=new ArrayList<>();//创建一个结果数组，存储数字集合，类似于list 你的vector
    for( int i = 0; i <str.length(); i++) {
        num = (int)(str.charAt(i)- '0');             //获取第i位的数字
        int index = binarySearch(numbers, num); //查找小于等于该数字的最大值在number中的下标
        //根据index来判断
        if (index == -1) { //说明不存在比其小或者等于的值，直接回溯，说明要前面已经选择的某一位数字缩小
            int index1 = i - 1;   //从后往前找第一个能够缩小的值，因为我们要取最大值，所以肯定是希望低位缩小一丢丢
            while(index1 >= 0) { //
                int temp = binarySearch(numbers, res.get(index1));
                if( temp != -1) { //找到了一个可以缩小的值，说明第index1位的数字可以缩小
                    //添加,下面的步骤其实就是添加这个数字辣！！！！！！！
                    res =res.subList(0,index1);
                    res.add(numbers[temp]); //因为这里index1取了一个比之前的小的值，所以index1后续的所有值都可以替换为number的最大值
                    for (int j = index1 + 1; j < str.length(); j++) {
                        res.add(numbers[numbers.length-1]); //添加number中的最大值
                    }
                    break; //退出辣！！！！！
                }
                index1--;
            }
            if (index1 >= 0) { //这里就是判断是否找到最小的值，如果这个index1<0 那么说明是因为循环条件不满足的才退出的，不是因为上面的break
                break;
            }
            //到这里发现不存在一个从后往前能缩小的值，那么只能将数字替换为比n的位数小一位的最大值，比如原来n是5位，那么我就取一个4位的数字辣！！！1
            res=new ArrayList<>();
            for (int j= 1; j <str.length(); j++) {
                res.add(numbers[numbers.length-1]);
            }
            break;
        } else {
            if (num == numbers[index]) { //存在一份相等的值，添加，往后走
                res.add(numbers[index]);  //添加
            } else { //小于，那么后面的所有数字都可以取最大的值
                res.add(numbers[index]); //添加
                for (int j = i+ 1; j < str.length(); j++) {
                    res.add(numbers[numbers.length-1]); //添加number中的最大值
                }
                break;
            }
        }
    }
    Syste`



## 1.如何保证服务器传给客户端的公钥是真的公钥，而不是中间人伪造的（如何判断证书是被伪造，权威机构的私钥无法被获取）

**证书认证的过程：一般权威机构认证中心都会给浏览器一个公钥，浏览器会使用公钥对证书解密得到服务端的公钥和证书的数字签名，用服务端的公钥解密数字签名之后得到证书信息摘要，经过hash算法计算出证书信息摘要，即可判断是否有人更改。**

**即使中间人解析出服务端的公钥和证书签名，并且进行更改，但是也没有权威机构的私钥来加密，所以说无法更改内容。**

**并且无法生成一个和服务端一样的证书。**



## 2.MySQL主从复制的过程

mysql主从：集群复制原理过程（从服务器去拉主服务器的数据）

1. 从服务器开始建立同步过程
2. 从服务器根据从主服务器上授权的用户权限请求连接master服务器，并且请求从指定binlog文件的指定位置之后发送binlog文件的日志内容
3. binlogDumpThread就会将指定文件的指定位置之后的内容返回给SlaveIO，返回内容还有就是服务端的新的binlog文件名称和下次更新位置。
4. 将binlog日志文件内容记录到relay log中，并将下次更新的文件和位置记录到master-info文件中，方便下次去读取的时候能够知道更新的binlog文件和位置。
5. SQL Thread会自动检测relay log的记录，并且自动解析成SQL语句。

**通过dump thread 写入binlog**->从服务器监听到变化去读取->回写relay log->SQL Thread读取。

问题：（主库宕机，数据可能就丢失了，还没来得及同步）而且从库是不能写的，主库写的压力大，可能存在一定的延迟，但是如果这个时候从库也大量的读操作。

解决方法：半同步复制和并行复制

**全同步复制：解决数据丢失问题，数据不一致问题：在提交事务之前，发送给从库，等等到所有的从库提交之后才能返回。**

**半同步复制：提交完事务之后，等至少一个从库写入Relay log之后才返回给客户端Ok**

如果半同步复制超时就会自动切换到异步模式。

**存在问题：**

​	**当事务已经在主机提交，还没到从机，主机就宕机了。这样客户端会再次发送一个事务到从机（备份恢复），主机连上来之后，也会同步刚刚的从机（新主机）这样原来的主机就会有了两份。**



解决方案：**基于loss-less的半同步复制：将等待从机的ack放在主库提交事务之前。**

**并行复制：解决延迟问题，从库的多线程，其实主要是增加从库的SQL Thread。**



双主双从：建议的是双写单读，因为会产生数据不一致的问题。

循环复制问题：双主互相复制新增的数据，例如A查入了一个ａ，B复制到了ａ，写入B的ｂｉｎｌｏｇ，这个时候就会检测到B的ｂｉｎｌｏｇ更新，就会发送给ａ，这个时候就会产生循环复制。

解决方法：将ｂｉｎｌｏｇ设置为发送过来的ｂｉｎｌｏｇ的ｓｅｒｖｅｒｉｄ，每次传来的ｂｉｎｌｏｇ先自己检查一下，如果是和自己的ｉｄ相同则丢弃，这样就解决了循环赋值问题。



**容错切换的话主要有两种方法：可靠性主从切换和可用性主从切换。**

可靠性：ｍｙｓｑｌ集群中是否可写主要是配置文件中的ｒｅａｄｏｎｌｙ，所以切换的时候，就是不停的去获取B的seconds_behind_master，这个值代表从库SQL线程处理主库binlog时落后的时间，如果为小于某个值就会将A设置为ｒｅａｄｏｎｌｙ＝ｔｒｕｅ，然后等待SBM到0，再切换为ｒｅａｄｏｎｌｙ＝ｆａｌｓｅ，再通过第三方空间将业务请求发送到B。



整个过程会存在一定的服务无法访问的时间，就是再SBM从某个特定值归零的过程中

**可用性：不等SBM＝０，直接转为写，但是这个时候会造成数据不一致情况，就好比A插入一个４记录，然后转为B，B还没同步４，这个时候又插入５，然后B先插入５，再同步４，这个时候A库同步B的５记录，A里面就是先插入４再插入５，B是先插入５后插入４。**

## 3.Redis主从复制过程

1.开启主，从服务器，配置文件配置哪个是主，哪个是从节点。

2.从服务器发起SYNC同步命令，当服务器收到命令的时候，会执行bgsave命令去备份数据（fork出一个子进程），在此期间主服务器接收到的写命令会写入缓冲区，而在从服务器还未同步完成的时候，是否回应客户端的请求就看自己的配置了。

3.当bgsave执行完了之后，就会开始发送快照文件给从服务器，从服务器就要丢弃掉自己的所有数据，然后开始写入该快照文件。

4.在主服务器发送完之后，从服务器就开始解析执行快照里面的命令，执行完了之后就会开始接收主服务器在发送快照期间的写命令发送过来。

5.从服务器开始接受写命令。完成之后就会开始主服务器接收到写命令，也会将写命令发送给从服务器。



注意：此时如果有另外一台从机B在同步，如果该B从服务器执行在第三步之后，也就是写入了快照文件，A服务器就会等待其同步完，否则就会只执型后三步同步。

​	**注意：断线恢复之后会增量复制和全复制里面筛选**。

在同步的过程中，会有一个master id给从服务器，在断线重连之后，如果slave判断当前的master id和原来的相等，就会执行一个增量同步，如果不相等就会执行一个全量同步。

**三个概念：主节点id，复制偏移量（执行一次写命令就+1然后同步给slave，也会+1），复制积压缓冲区（先进先出的队列）**

当我们断线重连，就会去判断主节点id是否和原来的相同，如果不相同，那么就全量复制

如果相同，判断偏移量是否相同，如果相同，就直接连接即可

如果不相同，会去master的复制积压缓冲区寻找slave的偏移量，这个时候如果存在，则发送ok+continue，增量同步，然后发送给从节点

如果不存在（表示落后的版本太多了）那么就全量同步。







**RDB的持久化，相当于执行bgsave的过程**





**在主从模式中，从机只能读，不可以写，当主机下线之后，整个集群就会不可以写入，当主机再次上线时，就会重新连上。**

**在哨兵模式下，会自动从死亡的主节点的从节点中竞选出新的主节点，其竞选算法为轮询查看每个从节点的优先级。**

**缺点：不能检测到从节点下线，存在多次主从复制，影响性能，无法实现动态扩容，在主节点宕机期间到新主节点选拔出来之前这段时间，都不能提供服务。**

**在哨兵模式下，有主观下线和客观下线，是要所有哨兵投票表决是否检测不到（超过一半）。**





**集群的故障转移：**

**这里先说明，把一个master和它的全部slave描述为一个group，故障转移是以group为单位的，集群故障转移的方式跟sentinel的实现很类似。**

**某个master节点一段时间没收到心跳响应，则集群内的master会把该节点标记为pfail，类似sentinel的sdown。**

**集群间的节点会交换相互的认识，超过一半master认为该异常master宕机，则这些master把异常master标记为fail，类似sentinel的odown。**

**fail消息会被master广播出来**。**group的slave收到fail消息后开始竞选成为master**。

竞选的方式跟sentinel选主的方式类似（sentinel选出主sentinel去给宕机的集群选择master节点），都是使用了**raft协议**，**slave会从其他的master拉取选票，票数最多的slave被选为新的master**，**新master会马上给集群内的其他节点发送pong消息，告知自己角色的提升。其他slave接着开始复制新master。等旧master上线后，发现新master的epoch高于自己，通过gossip消息交互，把自己变成了slave。**



## 4.缓存穿透，缓存雪崩，缓存击穿

缓存穿透：存在数据库中没有的值，这个时候缓存也会没有，如果不考虑这种情况，在查询缓存没有的情况下会去直接打到数据库。

解决：布隆过滤器过滤掉，或者将null暂时写入缓存，或者在代码之中过滤掉。

缓存雪崩：某个时间段内，缓存集体失效：将时间设置分散一点，另外如果用redis集群，**可以给key做一些备份，部署在别的机器上面，用来承担流量**。

然后就是一种如果redis失效的策略：这个就类似于我们的服务的熔断和降级，**我们可以通过乐观锁机制或者消息队列去访问数据库，控制到数据库的流量，尽量不要让全部的流量通过**。（项目太依赖于Redis，Redis失效之后的方案）

缓存击穿：热点key承受大量并发，突然失效：key设置为永不失效，然后也可以通过并发控制去限制流量请求访问数据库。

## 4.BIO NIO AIO（Linux的同步IO和异步IO） 

顺带一提，NIO使用的是JVM的直接内存，主要是基于channel和buffer（使用的就是Linux的零拷贝技术）。

零拷贝链接：https://blog.csdn.net/u013256816/article/details/52589524

一般的传输文件：

1. 用户态线程A调用read
2. 内核态将磁盘文件读取到read buffer
3. 内核态CPU将内核空间的read buffer拷贝到程序空间的buffer中
4. 用户态调用write
5. 内核态先将程序空间的Buffer拷贝到内核模式下的socket的buffer中
6. 内核最后将socket buffer的拷贝到网卡设备中。
7. 切换为用户态

存在4次上下文切换，以及4次数据复制。

使用NIO文件流：（linux 2.1版本）

1. java程序调用transferto()->linux调用sendfile
2. 内核态将文件从磁盘中拷贝到read buffer
3. 内核态将文件从read buffer拷贝到socket buffer
4. 内核态将文件从socket buffer拷贝到网卡设备
5. 切换回用户态

可以看到这里减少了2次上下文切换，并且减少了从内核空间复制到程序，再从程序复制到内核空间的过程。也就是如下的过程

1. 将数据从文件拷贝到内核buffer
2. 将内核buffer拷贝到scoket buffer
3. 将socketbuffer拷贝到网卡

但是我们可以发现，这里的其实还是存在没必要的复制，比如从文件到read buffer，再到socketbuffer，再到网卡。

linux2.4做出的改进是

1. 将文件从文件系统拷贝到内核buffer
2. 向socketbuffer中询问出当前socketbuff的数据所在的内核buffer的偏移量和位置。
3. 将数据从内核buffer直接拷贝到网卡设备中。



这里的同步还是异步，取决于数据拷贝的时候进程可不可以做自己的事。

网络读取主要就是IO等待和IO读取，其中IO等待一般消耗的时间最多。（等待数据到来+数据从内核空间复制到用户空间）

**BIO调用recvform**

BIO方式适用于**连接数目比较小且固定的架构，这种方式对服务器资源要求比较高，并发局限于应用中**，JDK1.4以前的唯一选择，但程序直观简单易理解。

BIO就是程序发起对数据的IO读取请求之后，会一直 阻塞到数据从linux接收网络数据，然后内核拷贝到用户态的内存的过程中都会阻塞。（等待数据的时候也阻塞，不做其他的事）。



NIO方式适用于连接数目多且连接比较短（轻操作）的架构，比如聊天服务器，并发局限于应用中，编程比较复杂，JDK1.4开始支持。

**NIO和BIO不同的是，NIO将一个大的时间片分成好几个小的 时间片，就是所，会定时轮询的去询问数据是否准备好（询问的过程是阻塞的），两次询问的间隔期间可以干点别的事。**因为每次都是会去轮询调用系统调用，所以就会存在很多次内核态和用户态的转换。

注意：这里NIO就是用户进程去不停的主动的去询问是否准备好，将第一个阶段的过程分成了不同的时间片。

IO多路复用，本质上是一种同步非阻塞的IO，将NIO中的不停的询问换了一种方式：通过一个进程监听多个IO事件，充分利用进程资源。和BIO的区别就是，BIO在等待数据的过程中，得等所有的数据都到了之后，才会开始执行读取的操作。而IO多路复用是socket中的数据到了一点点就开始读取数据。（原理都是不断轮询所有的fds，IO事件）

当进程调用select，poll和epoll的时候，就会阻塞进程，同时内核会监视所有select负责的socket，当有一个准备好就会去返回。

如果线程比较少，那么其实通过多线程和BIO的效率可能会更高，因为BIO只需要调用一次系统调用receform，而IO多路复用需要调用两次recvform和select。

**但是系统开销小啊！！！！**

分为select，poll和epoll，其中epoll最重要。

主要用于：服务器需要同时处理多个套接字，通过单线程一次性处理多个请求，同步阻塞模式。



**AIO方式适用于连接数目多且连接时间比较长（重操作）的架构，比如相册服务器，充分调用OS参与并发操作，编程比较复杂，JDK7开始支持。**

AIO是所谓的异步IO，主要是发送之后然后由操作系统负责将数据接受过来保存在某个缓冲区，接收拷贝完毕之后提醒AIO的调用者（不需要自己的去接收数据，直接拿就行了）

（**操作系统帮你从内核内存拷贝到用户内存，不用你自己来参与，拷贝好了之后告诉你一声（通知的方式是信号）**）



重点的话说一说NIO：（Java的NIO就是基于Epoll来实现的）

NIO主要是由三部分组成：通道（允许通道上读和写，不需要两端同时读写，管道和管道之间传输，基本就是数据放入buffer，然后写入管道，然后从这个管道到另一个管道，另一个管道再写入buffer），缓存，和多路复用器。**传统的IO都是基于字符和字节的**，而**NIO是基于通道和缓存的**，数据之间都是从通道到缓存或者从缓存到通道。selector多路复用器的话就是监听多个通道的连接打开和关闭，所以NIO可以监听多个IO事件。

传统的IO是面象流的，**而NIO是面向缓冲区**。传统IO意味者从流中读取一个又一个的字节，直到去读所有的字节，没有被缓存到任何地方。NIO的缓存导向略有不同，数据读取到一个缓冲区，基于缓冲区就可以存储很久，并且可以继续写入其他数据。

**然后传统IO是一种阻塞的模型，当调用read和write的时候，就会去等待数据准备好，并且阻塞读取数据，而NIO不一样，NIO再数据没有准备好的时候可以干自己的事，例如去处理其他通道的写入，可以一个线程监听管理多个IO数据。**

## 5.Epoll和Select的区别（poll）

### Epoll和Select区别

主要区别就是：

1. select监听的fds是有限的，默认是1024个，是一个基于数组的存储结构，poll在此基础上做了改进，使用链表存储。但是select在其他方面和poll一样就效率很低了。epoll是基于红黑树存储的fds，理论上也是无限的，取决于你的内存。
2. select（poll）执行的过程是，首先将所有fds集合拷贝到内核空间，首先内核会去遍历fds集合，如果没有事件准备就绪（暂时没有数据传输过来）就会阻塞自己。当有数据来了之后，就会通知重新启动调用进程，并且再去遍历一遍fds，看看哪个事件准备就绪了。而epoll中引入了一种机制，首先就是在执行epoll_create的时候创建一个**eventpoll**对象，这个对象中存在一个RBR红黑树结构用来注册socket监听事件，而其中还有个rdlist就是存放准备好的一个socket事件（双向链表结构）。然后调用epoll_ctl来将需要监听的事件放入红黑树，并且引入了一个rdlist用来存储准备就绪的事件（通过epitem间接引用），同时通过WQ存放着阻塞着的进程，这样当epoll_await返回的时候就不用去再次遍历了，直接进rdlist找即可。
3. select和poll需要在用户态和内核态中不停的去复制拷贝fds，而epoll只用在开始的时候拷贝内存的fds，后续调用ctl添加新的socket就不需要来回拷贝所有fds了，但是对于rdlist还是拷贝的，

**边缘触发和水平触发：主要就是一个文件事件就绪之后，每次调用epoll都会通知（水平触发），边缘触发就是只触发一次，下次调用的时候就不通知了，边缘触发只支持非阻塞socket。**

而且我们也应该使用非阻塞的socket：因为如果当事件准备就绪epoll去调用的时候，如果这个时候客户端死了，迟迟没有请求过来，socket就会一直等待，直到建立了一个新的请求，这个时候socket就会等很久。

### LT和ET的区别

扩展：

（文件事件就绪）文件描述符的变化和文件是否可读/可写，如果文件操作符变了或者文件一直是可读可写，那么就一直是就绪状态。

如果我们使用LT模式，在读取这个文件的时候，仅仅只是输出查看该文件，那么下次调用await程序还是就绪状态，但是ET模式就不会这样，因为这个fds已经就绪过了，我已经通知你了，可以一定程度上避免事件的重复执行，当然坏处就是如果我们没有及时去响应，那么下次就不会通知我们了，会有一定的事件漏执行的可能。

LT模式：在读事件的时候，会去注册一个EPOLLIN事件，当这个事件触发会处理读。当写的时候会将数据写到fds中，如果是写事件，当缓存区写满了，就会注册一个EPOLLOUT事件，直到写操作完成。

ET模式：在读事件和写事件都得死循环的去读写，直到写完或者EAGAIN事件。

ET在每次都会清空就绪队列，而LT不会，就绪队列是一个链表形式的，所以说每次去获取就绪事件会更快一点，更加适合高并发的场景，但是记住一定不能使用阻塞IO，因为网络所带来的阻塞会使epoll陷入死循环。



在IO事件都不活跃的时候，select和poll性能会比较差，因为遍历的过程中其实大部分都是没有就绪的。但是如果是IO事件很活跃，连接数比较多，那么select和poll的性能就会比epoll好，毕竟epoll需要一定的函数调用。

## 6.TCP和UDP的区别，TCP如何保证有效传输

ACK=1，确认号字段才会有效。

TCP和UDP：（主要围绕可靠和不可靠，有连接和无连接，主要使用场景来回答）

一个有连接的可靠传输，一个是无连接的不可靠传输。

**连接在于TCP在通信前需要创建连接，完成之后需要断开连接。而UDP是不需要建立连接的，直接开始传输数据即可**

**可靠在于TCP保证在发送数据的时候报文无差错，不会乱序，不会丢失，不重复。而UDP只是保证报文不出错（通过校验和）**（可靠性主要依赖于ack确认和重传，流量控制和拥塞控制）

**TCP通过序列号机制，ack确认机制和重传机制（超时重传，累计确认，快重传（累计收到3个相同的ACK）），滑动窗口，拥塞控制来实现可靠传输。**

UDP具有很好的实时性，只用把报文发出去即可，不需要确认，所以说速度会比TCP快，主要用于需要一定的实时性但是又对数据的完整性要求没那么高的应用，就比如直播，语音电话之类的。

TCP只能点对点，而UDP可以一对多。

UDP的稳定性靠网络保障，只要网络好，而TCP对于信息数据的传输需要很多的确认，比如流量控制和拥塞控制之类的，所以说就会比较慢，对资源的利用率不会很高。

TCP适合我需要保证数据传输正确的应用，例如发送邮件，上传文件这种。

而UDP适合对实时性要求高，但是对数据的完整性没那么严格的应用，允许数据在一定程度上有丢失。

**如何保证有效传输：ACK机制，序列号机制，重传机制，流量控制机制，拥塞控制机制。**

## 6.滑动窗口

**如果说TCP每发送一次数据，都需要一次应答，那么效率会很低，但是如果说像选择重传一样，可以不停的发送，那么可能会存在接收端和发送端的流量接收速度不匹配的问题，那么就会收到很多相同的ACK，效率也就没那么高了。**

所以说，**为了能让TCP一次发送很多数据，也能够有一定的限制，TCP引入窗口的概念**，根据发送和接收方的不同，又称为发送窗口和接收窗口大小，而流量控制中就是使用的滑动窗口。

[0,500] 0-500 ，left now right(还没有收到ack的，现在发送到哪个了，最多可以发送的值)

并且说根据接收端返回的窗口大小，来动态调整自己的窗口。

拥塞控制：拥塞窗口，发送阈值：**65535个字节**，超时重传（重传计时器），快重传

## 6.TCP的粘包

连着发了两段数据，但是接收方合成了一段，没办法解析该数据。

UDP不会粘包，因为UDP协议有消息边界，消息边界的话就是说接收端接收到有消息边界的报文就会直接网上送，一次只能接收一个数据包。

只有TCP会粘包，因为TCP协议的性质，过大的报文会被分成一个个的报文段，而接收者在接收这些报文段的时候不是说接收一个就往应用层送一个，而是将过小的报文连接合并起来，实际上是因为接收者不知道发送者消息的多少。

当然也可能是发送区缓存还没满，然后tcp在发送区缓存没满的情况下接着发送数据包。

解决方案：

1. 在发送数据之前，先告诉接收者我要发多少数据，让他一次性接受完（这总情况可能会因为多发一个报文而放大网络拥塞）。
2. 以固定的长度发送消息，并且告诉他我后面还剩多少数据
3. 特殊标记法来标记报文。



## 6.TCP TIME_WAIT的作用

1.防止两个公用相同端口的TCP连接中的旧四元组的报文的影响（等待2MSL，足以让两个方向上的所有的报文全都失效）

2.防止最后一个ACK丢失导致服务器没办法正常关闭

TIME_WAIT过多：占用端口，可能会没有端口可用，消耗资源。

## 6.GET和POST，HEAD的区别

GET和POST只是一种RESTFUL风格的一种规范。

幂等性：一次或者多次请求对资源以及资源本身都有相同的结果。即请求不会对资源产生副作用，就算产生副作用，后面的即此请求的副作用只有一次。

GET请求一般是用来读请求

1. 发送的参数会显示在URL上，保密性不是很好，GET的请求长度是有限制的，虽然说HTTP没有规定过，但是一般的浏览器都会限制。
2. 一般都保证幂等性（因为是读）GET会被浏览器缓存，如果说一直GET会直接返回缓存的内容。
   1. get请求有幂等性，这里是指get请求是读请求，不会有一定的副作用，例如post，put和delete都会对服务器文件来做一定的修改。
   2. **get请求会被浏览器缓存，如果再次get请求，会直接返回304（请求资源未修改），不会请求服务器**
3. GET只产生一个数据包

```
GET /chinesenation//nation/nation/nation?nationName=汉族 HTTP/1.1
Host: localhost:58082
Content-Type: application/json
Content-Length: 41
Connection :keepalive
User-Agent: 客户访问的环境，
Cookie：如果服务器使用cookie认证的话

{"num":"16347309998522553","action_id":2}
```

POST一般用来写请求，提交的是一个表单数据（参数不会在URL上展示）

1. 发送的内容放在请求数据中，并且没有长度限制，不会显示参数。
2. 一般不保证幂等性，浏览器也不会缓存。
   1. post的url不是创建资源本身，而是一个资源的接收者。
   2. put请求一般都是创建资源的本身，所以put请求是有幂等性的。
3. **会产生两个数据包**，第一次先将请求头发给服务器，服务器返回100（提示信息，标识协议处理的中间状态），标识可以继续操作，然后再将请求体发给服务器。

```http
POST /chinesenation//nation/nation/nation HTTP/1.1
Host: localhost:58082
Content-Length: 314
Content-Type: multipart/form-data; boundary=----WebKitFormBoundary7MA4YWxkTrZu0gW

----WebKitFormBoundary7MA4YWxkTrZu0gW
Content-Disposition: form-data; name="file"; filename="/C:/Users/更科瑠夏/Desktop/平衡仪测试数据集合/temp/1638353721381-1-0.txt"
Content-Type: text/plain

(data)
----WebKitFormBoundary7MA4YWxkTrZu0gW
Content-Disposition: form-data; name="user
"

1234
----WebKitFormBoundary7MA4YWxkTrZu0gW
```

响应报文格式

```
状态行
响应头部（）

响应包体
```

HEAD：一般只需要响应头部信息，利用这个方法就不用传递整个资源内容，一般用来验证超链接的有效性。

## 6.如何实现UDP可靠通讯

只能基于应用层协议来解决UDP可靠通讯

发送发：包的分片，包的确认和包的重发。

接收方：包的确认，包的调序。

RTP

## 7.进程同步的方式（本质上是进程中的线程来同步）

小扩展：线程同步：临界区（多线程访问同一个代码块），互斥量（通过多线程修改同一个变量，mutex），信号量（），事件（响应事件，比如AQS里面的conditional）

### **信号量（计数器）**

用于进程之间传递信号的一个整数数值，**主要控制对共享资源的方法，PV操作原语**

可以通过PV操作同一个信号量来实现进程的同步，例如通过P操作使信号量-1，如果此时为0，则阻塞进程，另外当信号量变为1，则解除阻塞。

### 管程

信号量机制问题：每次访问临界资源都需要进程自身执行PV操作，当不同的进程去分别各自执行，就很容易照成系统的死锁。

而管程的出现就很好的解决了这个问题，**它相当于把对所有信号量的操作统一封装起来，供别的进程调用**。

引入了条件变量和等待队列，管程具有互斥性：任意时刻管程中只能有一个活跃进程。

条件变量就类似于Java里面的AQS的condition，涉及理念是差不多的，就是当进程因为某些原因阻塞的时候，将其加入对应条件变量的等待队列中，并且释放管程，当条件变量被激活时：满足条件，则会去唤醒所有在等待队列中的进程。

### 消息传递-生产者消费者模型

**消息传递的实际功能也是以原语的方式receive和send，好处就在于可以给指定的进程发消息。**



## 8.进程通讯的方式

管道：（半双工，只能单向流动，无名管道只能在有血缘关系的进程之间通信，实际上为内核缓冲区，进程创建管道之后就会获得两个文件描述符的引用，fork子进程之后就会得到这两个文件描述符，在通信之后就被删除，**最主要的特点是会阻塞**）

注意：管道存在于内存中，而命名管道存在于磁盘文件系统中。

命名管道：在管道的基础上优化了以下，命名管道相当于在文件系统创建，这样就算没有血缘关系的进程也能通过管道名找到管道的文件描述符。

信号：**信号是一种比较复杂的通信方式，他一般就像传递消息一样，用于通知某个事件发生，让该进程执行对应的操作。本质是软件中断**，比如nginx中master进程和work进程之间的通讯就是这样，又好比linux在部署环境时，我们一般都用kill -9 去停止一个进程，这个-9就是一个信号，又好比在**AIO通讯中，当操作系统把接收到的数据拷贝到用户内存之后，也是通过信号去通知对应调用的进程。**

**信号量：计数器**，主要是用来进程同步，或者是对共享资源的访问，常常作为一种锁机制。

消息队列：进程可以通过消息队列通讯，消息队列实质上就是一个链表结构，然后改变了信号传递信息少、管道只能**传递无符号字节流的**特点，消息队列可以传递指定的消息类型，并且接收方可以根据消息类型来选择性接收。另外消息队列可以独立于进程存在，你需要的时候去读取就行了。不适合较大的消息传输，消息一般都有大小限制。

共享内存：**由一个进程去创建的一块内存，其他进程可见，将自己的地址空间和实际内存的地址做了一个地址映射，这样每个进程都能直接操作这片共享内存，不像管道我们需要去read和write操作，使用地址就能完成I/O操作，减少了数据发送接收的消耗，这是一种最快的方式，一般就是配合信号量做进程的同步。最快的，因为不需要数据的拷贝，直接通过地址去操作内存**。

**Socket：主要用于不同机器上进程的通信，依赖于网络。**

## 9.网络的5层和7层

应用层，表示层（不同的机器采取的编码方式，可能使用的数据结构也不同，表示层就是对这些数据进行翻译，使用标准的编码方式，另外还可以对分组进行数据压缩），会话层（主要是系统之间建立会话请求，通过传输层提供的端到端的服务，进一步有序的传递数据，主要就是对会话同步，包括说建立管理终止进程之间的会话），传输层，网络层，数据链路层，物理层。

应用层+传输层+网络层+数据链路层+物理层。 （报文，报文段，IP数据报，帧，比特）

**应用层主要就是为进程提供服务**，http协议，ftp协议，smtp协议，dhcp协议,DNS。

**传输层就是负责为两个主机的进程之间的通讯提供服务**，单位是TCP报文段和UDP用户数据报，分为复用和分用，就是说在传输的过程中可以公用成统一的打包发送出去，交给上一层的时候就将其分开发送，类似于在传输层通道之间封装在一起发送，公用一条管道。ip和端口号

**网络层：将数据报，每个分组从源端传到目的端，路由转发的功能，以此实现网络互连**。（广域网中最高就到这一层了，AS自治系统,OSPF,BGP）

**数据链路层：提供点对点的通信，传输单位为帧，主要功能是通过各种控制协议,将有差错的物理信道变为无差错的、能可靠传输数据针的数据链路。**（帧的确认机制：停止等待和滑动窗口（ARQ协议（停止等待，回退N帧，选择重传）））（在局域网中的最高层）。将IP数据包封装成帧，并且实现差错控制，流量控制和传输管理。

**物理层：**传输比特（网线），透明传输，主要是在物理介质上，透明的传输比特流。



**OSI参考模型网络层支持无连接和面象连接的通信，而传输层仅有面象连接的通信。而TCP/IP协议就**是任务可靠性是端到端的问题，在传输层仅仅是无连接的通信，而在传输层就可以用有连接也可以用无连接的通讯。

## 10.Http1.0 2.0 3.0的区别和改进，Http2.0如何做到多路复用，Http3.0对2.0做了哪些优化

### 1.0

Http1.0 是一种无状态，无连接的应用层协议（规定浏览器和服务端只能保证短暂的连接）（无状态指建立连接，传输数据都是独立的过程，不会去记录过去的请求的参数）。

所以说每次都要去建立TCP连接，并且还不能并行，下个请求得等上个Http请求完成。

Http1.1就支持了长连接，**并且支持管道化（可以并行传输请求，但是并不是真正的并行，顺序不能打乱，并且服务端处理请求的数据也不能乱，队首阻塞问题）**。

所以说现在的浏览器默认是不支持管道的。

### 2.0（现在浏览器使用的）

2.0在应用层和传输层之间加入了**二进制分层帧**，主要是实现了多路复用，实现真正的并行。

所有通讯都在一个TCP连接上完成，每个请求基于一个stream的流，每个流都有一个唯一的id，用来标识不同的请求，基础的单位为帧。

将数据封装成一个个的帧发送，每个帧都会标识出所在的流，所以说不会乱序，并且在多路复用中可以设置优先级。

**还包括可以对http请求的header头部压缩。**

如何实现的多路复用：**通过帧对数据进行了顺序标识（不同的请求有不同的流id），这样收到数据之后可以按照序列对数据进行合并（同一个帧称为一个消息），就是因为有了序列，所以才能并行的传输数据**。

### 3.0

**因为使用的是同一个tcp连接，但是当连接出现丢包的情况，就会导致TCP要开始等待重传，因为说TCP是保证时序的，所以后面的所有数据就会被阻塞。**（因为此时必须要重传丢失的包，导致后面的包无法传输，就好比S1 S2和S3 P1 P2 和P3，这个时候我传输过去了S1 S2 P1 ，S3丢失了，所以TCP要重发S3，那么就没办法发送P2，就会导致后面的流无法去使用）

在Http3.0所做的改进是：没有使用TCP协议，而是基于UDP协议的**QUIC**协议。



基于UDP：当有个丢包的时候只用重发就行了，不需要重传整个连接，也就不会造成阻塞了。

自定义连接机制：IP改变了会重新建立TCP连接，QUIC之间会维持一个通信ID，只要ID没有变，连接就还会存在。

QUIC有个很好的性质就是：向前纠错机制，当有包丢失的时候，会将该包直接组装到其他包的后面，而无需重传（当丢的包较少的时候，确认机制可以类似于：发送三个包之后，计算该三个包的校验包，也就是发四个包，其中如果出现了丢失，那么就会通过校验和计算出丢失数据包的内容，然后下次发送的时候添加到别的包后面。但是如果丢包太多，比如33个里面丢了两个，那么就得重传了）。



## 11.浏览器输入一个域名之后会发生什么

1. 首先浏览器会判断你输入的内容，如果输入的是类似于.com这种，那么就会认定你是输入的网址而不是需要搜索的内容。
2. 然后如果你没有添加的话就会默认去添加成http协议或者https协议，并且使用get的方式。
3. 首先会查询浏览器缓存->系统缓存->路由器缓存有没有该dns解析的域名，如果有就直接用，如果没有就回去调用DNS域名解析服务(这相当于也是发起一次查询)。然后就会去使用DNS解析协议解析该域名，并且获取到IP地址，然后浏览器就会根据这个ip地址和默认的端口号80端口去发起一个请求，即http://ip:80去请求，然后往下进去传输层，传输层开始建立TCP连接，TCP三次握手。
   1. 请求行类似于：GET http://www.baidu.com/HTTP/1.1
4. 此时TCP的报文头中为 源端口 目的端口浏览器的源端口由浏览器默认随机。
5. 在三次握手之后，TCP开始传输数据请求，传输层将报文封装程为报文段，往下发送出去。
6. 网络层将传输层发过来的报文封装成IP数据包，并且根据IP地址去进行路由和寻找， 往下交给数据链路层。ARP协议将ip地址转换为mac地址，路由器可能使用ospf协议来更新本自治系统的路由状态，方便进行路由转发。可能还会有NAT协议来将私有ip地址转换为共有ip地址。
7. 数据链路层将ip数据包封装成一个个的帧，通过邻居协议寻找mac地址，然后ARP请求查找目的地址（将IP转换为mac地址，广播去询问局域网的所有主机），如果在局域网找不到，就会替换为路由器的mac地址，然后将目的mac变为路由器的地址。
8. 物理层传输。
9. 路由器接收到mac请求，根据ip去广域网询问目的ip的mac地址（ARP协议），找到了之后将目的mac变成该主机的（可能也会是个路由器），并将源mac替换为该路由器的mac，就直接发送过去。
10. 服务器收到该帧，然后不停的解析，解析出请求体和源ip的端口，然后上交给应用层，应用层目的进程接收到该请求，然后返回相应的数据。
11. 然后数据返回的过程就和数据发送是一样的了。
12. 数据传输完毕之后，TCP连接释放。
13. 浏览器解析收到的html文件和js文件，显示给用户。

## 12.MySQL和Redis，MongDB等NoSQL的对比。

MySQL中存的是关系型的数据，也可以称作结构化的数据，数据保存在磁盘上，读取数据都需要磁盘I/O，读取较慢，主要是用于存储。

MySQL执行过程：简单而言->连接器->查询缓存->分析器->优化器->执行器

正是因为数据全都存在磁盘上，所以说每次的读请求都是磁盘IO，因为磁盘IO包括机械臂的上下移动以及寻道的时间，这个对于软件所花费的时间来说是很长的，所以其读写效率不高，后来引入了缓冲池的概念，去暂时将部分数据放在缓冲区。

但是mysql的内存能存的数据终将有限，而且频繁的查询很容易造成

预读失败**（预读：局部性原理，将可能用到的数据预读到缓冲区，预读失败：将预读的页读到缓冲区之后，mysql并没有读取这个页，解决方法：起初加入到老年代，只有真的读取才会移动到新生代，此时新生代的最后一个页会被移动到老年代，所以这个过程中并不会有页面移出LRU队列）**

以及

缓冲池污染（缓冲池污染：旧的数据一下子全都被大查询所查询出来的新的数据替换了，解决方法：**加入老年代等待时间的概念，如果说数据在队列中停留时间大于某个值并且被二次访问过，才会被加入新生代**）

所以说效率其实没有提多高，因为mysql不是一个强调内存的数据库，主要功能是存储和条件查询。



MySQL对于数据的条件查询更加占优，而Redis基本不支持条件查询，keys *?MySQL的事务，索引都比较完善，而Redis的事务其实都不叫事务。

Redis的话，是基于key/value的一个noSQL型数据库，主要的作用不是存存储而是做缓存，是一个基于内存的，更偏向于内存操作的数据库，而且是单线程执行读写操作的数据库，正是因为基于单线程，不需要进行过多的线程切换的上下文切换，并且引入了epoll，IO多路复用，一个线程监听多个事件，并且基于数据的读写操作都是在内存里面操作，所以对于查询修改以及简单的读取来说，Redis更加优。

NoSQL的话适合存储一些增长快，插入多，修改少的非结构化数据，通常都需要按key获取的效率高。

MongoDB是一个分布式文档存储数据库，主要用于存储内存大，多但是价值低的数据，例如说网页的缓存，存储冷数据。



## 13.如何优化MySQL查询效率

**冗余字段（反范式），静态资源，缓存，（对于一些经常查询，写操作少的添加索引），优化字符串（垂直分表），做一个主从（分担读操作的压力）**

1. 适量的增加冗余字段，尽量减少表的连接操作，执行一些反范式操作。

2. 静态资源（可能一直都不会变得字段就别放在数据库中，每次调用的时候去查询了）

3. 增加索引，对于一些经常查询而修改很少的字段建立索引，尽量满足一个索引能匹配大多数请求，联合索引遵守最左匹配原则。

4. 不要加入过长的字符串，对于一些字符串建立索引时，尽量使用其多长的前缀，这个前缀最好能够尽量多的标识每个数据的特征，一般都是20个。

5. 增加一定的缓存，减少MySQL的压力，通过锁机制，降低对于MySQL的并发数（连接池机制也可以用）

6. 部署MySQL集群，防止单点故障，一多从或者双主双从，注意主从对性能的影响。

7. 分库分表，shardingjdbc，mycat。（达到了性能瓶颈，在数据多的情况下，如果没有命中索引，会直接查全表，并且数据多，对存储性能也会有一定的影响）

   1. 垂直分库，将不同的表尽量分散到不同的数据库之中，减少模块之间的互相影响。
   2. 表的列太多，并且列上有大数据，如果不垂直分表的话，那么尽量每次查询select的时候，能不获取这个字段就不要去获取这个字段。
   3. 最好就是去垂直分表。
   4. 水平分表类似于ES里面分片的概念，就是将一个行数太多的表分开，这个时候还可以将手动将冷热数据分离。这个其实是一个比较复杂的过程，在查询的时候就没那么容易了。

   

## 13.MySQL分库分表

1. 当数据量太多的时候，单机数据库就会产生一定的瓶颈，例如单点故障，很多请求打到一个数据库，磁盘IO耗时，可能会引起MySQL宕机，服务不可用。
2. 迁移麻烦。
3. Mysql链接数，也不太好用（可能会达到太大的一个瓶颈）。

所以说需要扩展MySQL的可用性

**垂直分库，垂直分表，水平分表。**

1. 垂直分库：将不同的模块分成不同模块的数据库（基本上，一个服务不回去访问另一个服务的数据库）
2. 垂直分表：将大表（列很多）分开，MySQL底层是通过**数据页**存储的，**一条记录占用空间过大会导致跨页，并且如果一条记录的大小还行，那么一页就会方更多行，可能程序下次命中就会更好，不用去找磁盘IO**（将一些太大，不太常用分开）
   1. 外键约束可能会受到影响
   2. 插入需要事务
   3. 无法处理表行太多。
3. 水平分表（将若干个按照某个条件相同的去分表，大表分成小表）
   1. 单库水平分表：单库分表就是在同一个数据库之中，将大表分成若干小表来存储。所有表还是放在一起，竞争的还是同一个机器的CPU，没有很好的去缓解压力
   2. **分库分表**：将单个表分到不同的库里面，并且说这些库可能还是有多个表。
      1. 优点：缓解MySQL的压力，提升稳定性，加快查询速度
      2. 缺点：排序不方便，查询不方便，分布式全局ID

比较常见的分库分表策略：

1. 根据时间区间：冷热数据分离
2. hash取模(hash算法)
3. 根据地区，特定的标志条件（省份）

带来的问题：分布式事务！！！（订单表和存款表不在一起，我需要去保证先扣存款后扣订单）

## 13.undo log，redo log，binlog的区别和写入时机

执行过程：

1. 提交的语句经过解析器解析和优化器优化，生成执行计划，然后通过执行器执行。

2. 先查询旧值，先看看内存有没有，从磁盘读取，放入buffer中，然后写入undo log。

3. 修改，执行，赋值，更新内存（buffer）中的数据。

4. 将修改写入redo log 这就是一个redo log准备的过程（这个阶段我们将其程为redo log prepare，标指为prepare）

5. 根据redo log自定义的刷盘策略去刷盘（一共有三种）
   1. 从redolog->logbuffer ->磁盘 	从log buffer是每秒写入osbuffer 并且调用刷盘到磁盘
   2. 从redolog->磁盘  **每次提交一步到位，从redolog到osbuffer在刷盘到磁盘（注意不是每s）**
   3. 从redolog->os buffer->磁盘 **每次提交写入osbuffer 然后每秒调用刷盘。**
   
   	**1.刷脏是随机IO，因为每次修改的数据位置随机，但写redo log是追加操作，属于顺序IO。**
   	**2.刷脏是以数据页（Page）为单位的，MySQL默认页大小是16KB，一个Page上一个小修改都要整页写入；而redo log中只包含真正需要写入的部分，无效IO大大减少。**
   
6. 写入binlog。

7. 把每次更新的binlog文件名称和这次更新的binlog日志在文件中的位置，写入redo log，之后在redo log中写入一个commit标志（redo log记录binlog的更新）

8. 提交事务



简而言之 ：

- undo log是为了实现事务的原子性，在数据修改之前，先记录原来的状态，然后再去修改，为数据回滚记录一个之前的值，并且在实现隔离性的方面也有大作用。

  undo log记录的是一个逻辑日志，理解为总是记录和执行语句相反的操作：例如insert对应delete update a->b变为update b->a

- redo log：当表数据发生修改的时候，innodb会先将记录写到redo log中，并且更新内存，此时更新就算完成了，他是一个环形文件，是循环写的（也是追加写入）空间会用完，主要用于保证数据库的持久性。

- **binlog：记录数据库所有表结构的变更和数据库表内容的修改的二进制日志文件，一般都是用来做备份系统，主要用于主从复制。**

- **binlog的话主要存储的是语句执行逻辑，是逻辑日志，而redolog是记录的变动，是物理日志，记录的是物理页的修改，而不是说什么行的修改。**

- binlog是mysql有的，而redo log是innodb独有的。

## 14.ES的索引结构，倒排索引细节，词典如何存储，倒排文件如何存储，词典如何优化存储，具体读写细节，ES集群的优化。

ES集群是一个中心化的集群。

### 排序

DocValue使用mmap创建一个内核缓冲区，将每个文件记录按照列存储映射进内存里面，这样对磁盘的IO操作就变成了对内存的操作，方便排序。

全文搜索：让非结构化的数据变得有结构化，更加方便查找。

Lucene就是一个工具包，方便让系统实现全文索引的功能，比较好的两种实现就有solr和elasticSearch。因为solr需要借助zookeeper进行分布式的协调管理，所以本项目中使用了elasticsearch

### 倒排索引

词条：单个的词，

词典：包含每个词条以及该词条指向的倒排表的指针

倒排表：记录某个词条的对应的文档的doc id，以及出现的位置和词频信息

词典+倒排文件（倒排表的集合）

分片和副本不会再同一个节点上，保证读操作的有负载。

### **写操作**

写操作路由：根据doc id的hash值计算出应该在的分片编号，然后去路由到该编号的节点上。

写操作是在内存中完成的，当数据在内存中被修改之后（新增+删除），就会生成一个新的段，当我们需要去添加时，只用在当前文档新增一个段即可，删除只用将该段记录到一个.del文件中，在筛选查询出需要查找的记录之后会去.del文件中过滤。所以说在查询的时候可能会查到两个版本的数据。

分段的好处：因为设置成为不同的段，所以在写操作可以一定程度上避免对锁的使用，使用文件系统缓存来暂存数据，避免了读请求直接打到磁盘。

坏处：因为延迟删除策略，所以会造成一定的空间浪费，特别是说如果有很多个修改的数据，并且说在每次查询完了之后还要去.del文件中删除已经被标记删除的项。

### 延迟写策略

内存->操作系统缓存->磁盘

在内存中并不是已段的格式保存，所以说在内存中并不提供读功能，当默认1s之后或者说内存数据打到一定的量，就会促发一次刷新，将内存的数据生成一个新的段缓存在文件系统之中，然后就可以提供搜索的功能了，这就是ES的一个延迟写的策略。

为了避免丢失，ES引入了translog文件，当记录被写入内存，同时也会将记录备份到日志文件之中，当日志数据超过512M或者超过30MIN之后，就会触发一次flush，生成一个提交点，内存的数据会被写入磁盘。在断电之后会根据translog去重新持久化到磁盘。

### 段合并

会定期执行段合并操作：小段被合并成一个大段，已经被删除的文档就会从文件系统中被清除。

### 集群优化

1. 首先节点分为master节点，数据节点和参与节点，可以同时为master节点和数据节点。
2. 尽量不要让一个节点同时为master节点和数据节点，因为数据节点对磁盘的要求会比较高，不要创建太多的分片，尽量不要超过9个，会影响集群的性能。
3. 增大心跳机制的时间，避免因为网络阻塞而产生多个数据不同的master节点，防止脑裂。
4. 合理的设置mapping，对于一些不需要分词的列设置为keyword。
5. 尝试冷热数据分离。
6. 批量提交读写请求。
7. 尽量不要使用DOC ID让系统自动生成去。

## 15.死锁产生的条件，破坏方式

死锁是值两个或者多个进程对共享资源的访问的情况下，由于竞争资源或者通信的过程造成双方的阻塞，如果没有外力帮助就没办法执行下去的情况

死锁预防：

1. 互斥资源：不可改变
2. 请求保持：可以一次性给该进程所有需要的资源。
3. 不可剥夺：当线程获取资源失败之后释放其所有资源。
4. 循环等待，存在环路。破坏环路条件，采取顺序资源分配法，进队列去获取资源。

## 16.消息队列的选型

ActiveMQ对于JMS支持最好，但是集群模式需要依赖zookeeper，kafka也要依赖。

然后就是rocketmq和kafka了，他们具有天然的集群支持，负载均衡支持。

RocketMQ只支持Java

**kafka和RabbitMQ选型（kafka一般是用来做日志分析）**

我想用死信队列和延迟队列，而kafka并没有很好的支持这两个东西，主要是使用死信队列和延迟队列做一个消息如果被拒绝了，或者消息等待太久而造成消息队列中堵塞，导致后来的消息都发送失败，主要是想知道哪些消息失败了，然后记录在日志里面（包括说哪些消息被限流了）。

包括说消息的优先级，优先级队列，kafka都不支持，并且rabbitmq是支持很多种语言，不像rocketmq只支持java。

**Kafka支持单个生产者分区单会话的幂等性，而RabbitMQ需要自己保证幂等性。**

虽然说rabbitmq在功能上可能比kafka做的更好，**但是Kafka的吞吐量要比RabbitMQ高出1至2个数量级，一般RabbitMQ的单机QPS在万级别之内，而Kafka的单机QPS可以维持在十万级别，甚至可以达到百万级**。

对于Kafka而言，**通过ISR（In-Sync-Replica）来保证多副本之间的同步**，并且支持强一致性语义（通过acks实现）。

RabbitMQ是通过镜像环形队列实现多副本及强一致性语义的。多副本可以保证在master节点宕机异常之后可以提升slave作为新的master而继续提供服务来保障可用性。

但是Rabbitmq使用erlang语言开发，对于说要深入底层的学习的话就有点困难了，而且其具体QPS也不如RocketMq和Kafka，但是比较契合本系统需要的数据量。



ActiveMq:依赖于zookeeper，并且可能存在消息的丢失。

**RocketMq和Kafka：消息队列的天花板级别，但是由于kafka对于AQS的很高，所以说有些功能就会欠缺，例如没有优先队列，死信队列，延迟队列这种概念，优点的话就在于在单生产者单会话能自己保证幂等性，并且天生自带集群。并且RocketMq是只支持java的，所以说pass了RocketMQ。**

在kafka和RabbitMq中选择，然后因为自己的项目两者都够用，在考虑到使用优先级消息。

AMQP模型：生产者，消费者，**交换机，队列**，路由key和绑定key。


## 17.进程和线程的区别

进程之间拥有独立的资源和代码块，是CPU资源分配的最小单位，而每个进程中都至少有一个线程，线程是那个真正去做事的。

**线程是CPU调度的最小单位，线程不具有资源，但是可以访问进程的资源。**

## 17.进程切换为何比线程切换慢

每个进程都有自己的虚拟内存空间，而线程是会共享虚拟地址空间的，所以一个进程中的线程进行线程切换时不涉及虚拟地址空间的转换。

**把虚拟地址转换为物理地址需要查找页表，而查询页表是一个很慢的过程**（**至少需要访问两次内存**）。

第一次访问页表，得到内存的块号，然后再根据块号去访问内存。

就是说将访问过的**页号和块号写入告诉缓冲寄存器中**，类似于一个cache。

因此通常使用Cache来缓存常用的地址映射，可以加速查找，这个cache就叫做快表。

**每个进程都拥有自己的虚拟空间**，**也有自己的页表**，当进程切换之后页表也要进行切换，页表切换后快表就失效了，那么虚拟地址映射到真实的地址就会变慢，表现出来的就是程序运行变慢，在同一个进程的线程中不需要。

**线程切换仅仅只用少量的CPU寄存器和栈区**

进程切换需要**程序计数器和其他寄存器，虚拟内存空间，页表，TLB快表失效**。

需要切换：**内核栈以及虚拟空间，页表。**



具体过程：

1. **保存处理机上下文，包括程序计数器和其他寄存器。**
2. **更新PCB信息**。
3. 把进程的PCB移入相应的队列，如就绪、在某事件阻塞等队列。
4. **选择另一个进程执行，并更新其PCB。**
5. 更新内存管理的数据结构，**更新地址空间，页表**。
6. **恢复处理机上下文。**



## 18.Redis的基本概念，对Redis的理解



**Redis基本概念，从基于内存，key/value，非关系型数据，单线程，IO多路复用去说。**

**为什么快：基于内存，单线程(不需要进行版本控制，不需要加一些额外的锁机制)，高效的数据结构（sds，ziplist，skipedlist）**，**IO多路复用的事件驱动模型**。

但是Redis的性能瓶颈在于网络和内存，对于内存我们可以多加一点内存，但是对于网络而言，就只能靠可靠的网络通信了，所以说就引入了多线程来进行网络读写。多线程部分只是用来处理网络数据的读写和协议解析，并不涉及命令的执行。

主要是基于内存和IO多路复用来提升了Redis的性能。

## 18.Redis的事件驱动模型

在Redis中是基于事件驱动的模型，redis通过IO多路复用处理多个事件，主要有文件时间和时间事件。

文件事件：Redis服务器是使用Socket和客户端进行连接，**而文件事件就是对socket套接字操作的抽象**。而服务端对这些文件事件的处理会加入epoll的fds队列。

当有fd准备就绪时，会将这些事件发往事件转发器，事件转发器就将其发往对应的handler，就好比读请求和写请求会发往不同的事件处理器。一般都会涉及到以下三个

1. 连接应答处理器（连接）
2. 命令请求处理器（读取socket的数据）
3. **命令回复处理器**（返回值）

**时间事件就是对一些定时任务的抽象，例如过期键清理时间，需要在指定的时间执行。**

时间事件是通过链表结构来存储的，但是其实只有一个时间时间serverCron，而且是一个循环时间事件。

**一个事件会先后顺序执行，不会出现抢占情况**，优先执行文件事件，再执行时间事件，文件事件的等待时间取决于到达最短的时间事件决定。

## 19.ZipList，QuickList，skipedList

ZipList用于list hash 以及zset的当元素比较少的时候的存储过程，主要是压缩空间节省内存，这里就是用一定的时间去换内存了。

set：小的时候是intset，大的时候是hashtable。



## 20.谈谈对Spring IOC和AOP的理解

IOC和AOP的话都是一种编程思想

IOC：**控制反转，这是一种编程思想，就是将原本我们程序中所要用到的对象都统一管理起来，我们要用的时候直接去容器里面取就可以**了。这样就大大减少了我们编码的任务，我们不需要再去手动创建对象。主要是通过依赖注入实现的（构造器注入，setter注入，基于注解注入）。一般都是通过java的反射机制注入。

bean的加载过程：java->beanDefinition->beanFactory->bean（提前暴露，create->polution->initBean）

AOP：AOP是一种面象切面的编程思想，**相对于传统的OOP那种一路向下的模式**，这种模式**就会产生一些横切性的问题**，就好比我们要使用记录函数运行时间，添加缓存或者事务操作，这些功能都与主要业务的关系不大，但是如果我们再每个函数都手写这些横切性功能，那么就会很麻烦，并且难以维护。

静态代理：编译时增强，生成一个新的代理类，做类的增强，运行的时候就是运行的新的代理类了。

动态代理：运行时增强。

AOP提供了一种横切的思想，**将函数分为几个横切点**，主要功能就是将这些横切性的东西与主要模块的功能分开，**不再用内嵌在执行函数里面，**达到解耦的目的。

AOP实现切面编程的主要手段是代理，主要有静态代理和动态代理，在java中静态代理就是aspect注解，会在编译器形成一个代理类。动态代理主要有基于JDK的动态代理（InvocationHandler ）和和CGLIB的动态代理（MethodIntercepter），jdk的动态代理只能代理接口，并且是通过实现接口的方式去实现类的增强，而cglib的话就是通过继承一个类来实现动态代理，**具体就是根据该类的字节码生成一个新的子类的cglib类得增强的字节码**。底层原理都是反射。

## 21.谈谈对SpringBoot的理解

springboot的话对于spring来说，简化了配置文件的配置，**当spring的业务庞大起来之后，xml文件会非常多，并且我们配过的都知道，一个空格都不能错，不然就启动不起来，并且还要去配置汤姆猫**。

SpringBoot将繁琐的配置文件删除，引入约定大于配置大于代码的思想，通过properties或者.yaml文件的方式来优化配置项，系统的bean可以自动读取到配置文件中的数值，我们不需要再去手动去写bean的xml配置文件，并且内嵌了汤姆猫。可以说是将开发的复杂性一下子降低了很多。

SpringCloud是基于SpringBoot的一种微服务架构的解决方案，提出了服务治理，负载均衡，服务降级服务熔断和服务限流，配置管理和网关等概念，提供了一个比较完整系统的微服务架构的思想。

## 22.谈谈对微服务的理解

微服务：微小，耦合度低，可扩展性强，可维护性强。

缺点：增加运维成本，需要导入大量的第三方组件。



## 22.SpringCloud和Dubbo的区别

Dubbo的话更偏向于一个标准的RPC框架，而**SpringCloud相当于提出了一套比较完整的微服务架构的解决方案**。

严格来说两者都有优劣，SpringCloud 抛弃了RPC通信而是使用了Http Rest的方式。Rest方式就比RPC更加灵活，它不需要两者的依赖，只需要一纸成文的规定，不存在代码级别的依赖。

## 23.服务的注册与发现逻辑

服务注册中心，然后有生产者服务，消费者服务，监控服务，限流，服务熔断，服务降级，负载均衡，配置管理。

1.服务注册中心启动

2.生产者服务去在服务注册中心注册自己的服务，（id，ip，端口）。

3.消费者去服务中心注册，并且获得所需要的服务的可选列表，并且注册监听事件，然后将服务列表放入自己的jvm缓存之中，当服务端的服务发生变化时，就会更新本地jvm缓存。

4.本质上，从服务注册中心拿到的是某个服务（id，ip，端口）

5.当消费者想要去调用该服务时，就会根据指定的负载均衡算法，选择一个服务，根据ip和端口去调用服务。

## 24.RPC远程服务过程

实质上是一种客户端可以像调用本地函数一样调用服务端的函数。

**RCP远程调用本质是提供一种轻量的，无感知的跨进程通信方式**。

具体过程：

1. **客户端调用函数**（待调用的函数名+接口名，函数的形参和接受返回结果的指针）
2. 客户端将（函数名和接口名，函数的形参和函数的返回值）打包成序列化数据，并且将序列化数据发送给服务端（消息编码和解码，中间可能存在负载均衡，请求过滤，限流和熔断和降级过程）
3. 将序列化之后的数据通过网络传输到服务端。
4. 服务端反序列化客户端传来的数据，并且根据客户端传的参数去寻找要调用的方法。
5. 将函数的执行结果序列化为二进制数据。
6. 客户端接收到二进制数据，解析并且返回结果。

## 25.Bean的加载过程

实例化->属性注入->初始化->使用注入->销毁。

## 26.Linux内核态和用户态

**内核是一种特殊的软件程序，控制计算机硬件资源，例如cpu的调用，磁盘文件的读取。**

**用户态就是提供给应用程序运行的空间**，为了方便应用程序能够访问到内核管理的资源，例如cpu和内存，内核就必须提供一定的接口，这些接口就是被称作系统调用。

内核态和用户态：权限不同

内核通过提供一定的接口来规范用户操作CPU，来使用内存。我们都知道一个系统的资源是有限的，所以就需要操作系统对这些资源进行管理，如果说没有内核态，那么用户态就可以随意的去使用资源，导致系统资源耗尽，CPU100%。

**并且可能说如果不加以限制可能会存在一定的访问冲突**。所以说Linux设计两个权限不同的等级，就是所谓的内核和用户态。用户态运行的线程收到了很大的约束，只能根据内核给出的系统调用来执行相应的操作，而内核态的进程那就是“为所欲为”

**切换：1.系统调用 2.异常响应：例如缺页异常 3.外设中断，例如网卡有数据传来。**

## 26.内核态到用户态的切换

1. 用户态把一些数据放到寄存器，或者创建对应的堆栈，表明需要操作系统提供的服务（记录当前执行到的指令）。
2. 用户态执行系统调用（系统调用是操作系统的最小功能单位）。
3. CPU切换到内核态，**跳到对应的内存指定的位置执行指令**。
4. **系统调用处理器去读取我们先前放到内存的数据参数，执行程序的请求**。
5. 调用完成，操作系统重置CPU为用户态返回结果，并执行下个指令。
  

**进程只有在内核态才能访问内核空间，其余时间只能访问用户空间，每个进程的虚拟空间3-4G是相同的。**

## 27.ICMP报文

查询状态报文和差错报告报文

## 28.如何排查CPU100%的问题

linux

top -c命令显示最高的运行的进程数。

根据进程ID

top -Hp 进程ID 显示最高的线程数(大写的H，小写的p)

定位线程然后根据线程去查看堆栈信息

```bash
jstack 进程ID | grep '线程ID（16进制）' -C5 --color
```

## 29.内存溢出

如何排查内存溢出问题

堆溢出：（创建太多对象，内存泄露，无法回收）

1. **可能存在大量的对象创建，就比如说一次性从数据库中取出太多的值，打满了内存**。
2. 内存泄漏，无法回收，被别的集合引用的对象存在泄露（ThreadLocal）。
3. 初始堆值设置的太小了。

栈溢出：

1. 栈帧设置的太小（导致无法分配对象）
2. 虚拟机栈内存小，导致无法分配更多的栈

方法区溢出：

1. 创建大量的常量
2. CGLIB导致生成了很多的.class文件。

分析快照文件（JConsul）。

## 30.IP报文和TCP报文

版本号，首部长度（固定首部是20字节），整个IP报文长度，ip报文的序号，是否可以分片，是否后面还有分片，TTL（经过的路由器数目），记录协议（TCP,UDP,ICMP），校验和，源IP，目的IP。

TCP报文：源端口，目的端口，序列号(seq)，确认号(ack)，头部长度（4bit），SYN ACK RST FIN ，滑动窗口的大小，校验和和紧急指针。

UDP报文：源端口，目的端口，长度（报文头和数据）和检验和。

## 31.JWT和Session ，Cookie的区别

因为Http是无状态的，他不会去记录用户的身份信息，所以我们如果说要进行用户的身份认证，得去进行一些额外的操作。

Cookie和Session，其本质都是使用Cookie，Cookie将信息保存在浏览器，而Session将登录信息保存在服务器中。

SessionId也是放在cookie中。

Cookie使用key/value的形式保存用户的状态，很容易被攻击，除非你加密

Cookie和Session

1. **只针对浏览器，很多移动设备是没有Cookie的**
2. Cookie是客户端保存用户信息的一种机制，用来记录用户的一些信息，也是实现Session的一种方式。
3. Seesion的话就是服务器保存用户信息，只用给我一个sessionId即可。
4. Cookie保存的信息少，只有4K，Session保存信息多，但是存在服务端（但是保证了数据的安全性），占地方，并且在分布式中可能还存在session共享的问题（可以存在redis中，但是这样就让一些没有用到redis的应用白白加了一个中间件）
5. **通常情况下session的sessionId需要放到cookie字段中，如果cookie禁用了，那么可以通过URL重写技术，将sessionId放到URL尾部。**

JWT就**是一种无状态的认证，不需要在服务器保存信息，以JSON加密保存在客户端，并且跨语言，适合移动端，就算cookie被禁用，也没问题**。

JWT存在的问题：无法很好的解决用户主动下线的问题，token过期问题。

由三部分组成：header.payload.签名（没有经过加密的）

其中header只表示使用的什么算法。

payload的话存的就是用户的一些想要保存的信息，比如说我们要存的用户的登录账号，生成时间和过期时间，因为JWT是使用base64明文加密，所以说最好不要在这里放一些隐私数据。

然后最后一部分就是签名了，根据head和payload的信息以及服务端密钥的信息，根据指定的hash算法计算出特定的签名（），然后发送给客户端。我们项目中使用的SHA256算法。（RSA，但是RSA是一种非对称加密算法）



payload是明文，所以说还是可能被解密，这个时候其实我们可以将payload加密。（对称算法和非对称算法）



## 32.HTTP请求状态码

2xx，请求成功，200 请求成功，206 一般用于断点续传的实现。201 post请求结果，表示服务器已经创建了一个或者多个资源。

100 表示收到请求，处于一个中间过程，例如post请求先发头 再发请求体，中间就会返回100

3xx，表示重定向，需要进一步完成操作以完成请求。

**301 表示请求的资源已经永久重定向，并且会返回新的URL，浏览器会去自动定向到URL**

**302 与301 类似，要求客户端执行临时重定向，但是资源一般都是被临时移动，客户端持有的还是原来的URL。**

**303：对应当前请求的响应可以在另一个URI上被找到，当响应于POST（或PUT / DELETE）接收到响应时，客户端应该假定服务器已经收到数据，并且应该使用单独的GET消息发出重定向。**

**304 使用客户端缓存，表示请求的资源没有改变的时候。**

**400 客户端语法错误，服务端无法理解。**

401 **请求要求身份认证**

403 **服务器理解用户端请求，但是拒绝执行**

404 **服务端无法根据客户端请求找到页面。**

405 **请求类型被禁止**（比如get方法传post请求，post方法用get请求）Method Not Allow



500 **一般都是服务器错误，例如500表示服务器内部错误，内部执行异常**。

**501 服务器不支持请求的功能**，无法完成请求。

**502 作为网关代理，服务器传回来的响应无效。**

**503 超载或者说系统维护，服务器暂时没办法处理客户端的请求**。

**504  网关连不上服务器**。

**505 服务器不支持的Http协议版本**

## 33.Raft算法



## 34.如果出现大量的time-waiter状态，如何处理

1. 尽量使用长连接，复用TCP链接，减少time-wait
2. 减少time-waiter的时间。
3. 复用timewaiter的socket套接字。

## 36.Linux常用命令

awk，ps -ef |grep java ,vim,cat touch,cd ,sudo,mv,cp,rm,netstat,lsof -i ,top 

## 37.操作系统的任务

1. 资源分配，资源回收
2. 为上层应用程序提供服务，管理应用程序
3. 操作系统内核的功能
   1. 进程调度
   2. 内存管理
   3. 硬件通信
   4. 系统调用

## 38.Linux文件描述符是什么

Linux里面一切皆为文件，**一个Linux进程启动之后，会去创建一个PCB控制块，内部有一个文件描述符表，记录着当前的进程所有可用的文件描述符，也就是当前进程所打开的所有文件**。

其中其实还有两个表，打开文件表和inode表，其中打开文件表和inode表一个系统只有一个。

文件描述符可以存了各个文件的，文件指针，根据文件指针我们可以从系统的打开文件表获取到

1. 文件的偏移量
2. 状态标志（只读，只写等等）
3. inode表的指针。

然后我们可以根据inode表的指针进入inode表，该表存有如下信息：

1. **文件类型**
2. **文件大小**
3. **时间戳（更新和创建时间）**
4. **文件锁**

不同进程的不同的文件描述符可能会定位到一个文件，相同的文件描述符可能会定位到不同的文件。

## 39.子进程和父进程会共享什么

最基本的 

1. **文件描述符表**
2. **所有的环境变量**
3. **代码块**
4. **堆栈块**
5. **数据段**

不会共享：

1. 进程的PID，每个进程的PID都不相同
2. 父进程对某个文件的记录锁
3. 会将数据拷贝一份，子进程会在拷贝的数据上操作。

## 39.线程可以共享进程的哪些资源

1. **进程的代码块**
2. **进程打开的文件描述符**
3. **地址空间**
4. **堆空间**
5. **信号以及信号服务程序**

**不可共享：线程ID，程序计数器，线程自己的栈空间，线程自己的优先级。**

## 40.Java中的CAS原理

unsafe方法，调用的CAS是一个native方法，unsafe主要是获取某个属性在类文件的中的偏移量。

该JNI需要4个参数：对象，偏移量，期望值，修改值。

JNI的实现：通过该对象的地址以及偏移量的地址，获取到该值的地址，然后通过执行cmpxchgl指令，将值更新为修改值，然后其实还加了一个lock指令，用来锁住该缓存行。

分为总线锁定和缓存行锁定，**前一个会锁住总线bus，可能会造成请求阻塞的问题**，后一个是锁住CPU的缓存行，锁缓存行的话就是**当CPU缓存更新并且写回内存之后**，**其他CPU设备会通过总线了解到缓存失效，然后重新去内存里面读取最新的值**。（不让多个CPU同时修改一个数据）

## 41.Java中的System.arrayCopy

也是JNI的方法，其实有五个值：源数组，开始复制的下标，目的数组，开始插入的下标，要复制的长度。

首先会判断两者是基本类型还是引用类型。

然后判断是哪种基本类型：char，int就根据字节数目来复制。

如果是对象数组，那么是直接传递引用。

## 42.Redis的Zset的实现原理（默认降序）

命令：zrank，zrange，zrangebyscore，zincrby

当元素数量小于128个并且所有成员的长度都小于64字节的时候使用：ziplist

像其他数据结构的变得阈值是512和64

ziplist的话，和hash一样，都是member和score，集合顺序按照score从小到大排序，score在表头的位置。

ziplist：（默认配置下）

1. zlbytes：整个压缩列表的字节数（4B）
2. zllen：节点数目（2个字节），所以说如果值全为1，就得手动去遍历寻找长度
3. zltail：尾节点的偏移量
4. entry：具体节点（prelen，encode，data）
   1. prelen：如果前一个节点的长度小于254：那么这个地址占1字节，否则占5字节，第一个为254，后面的4个字节用来保存长度
   2. encoding：保存数据长度：（并且根据数据长度有不同的格式）
   3. data：具体的数据
5. zlend：用来标志结束。

list使用这个push和pull的时间复杂度就很低 o(1)。

为什么这个时候需要ziplist：就是说，当节点比较少的时候，使用跳表会建立很多的索引，可能会造成更多的内存浪费，并且在节点数比较少的时候，谁又说o(n)一定比o(logn)慢很多呢，所以说在节点比较少的时候，就留出一点空间。

如果使用skiplist结构的话，一个zset是有两个的，含有一个hash表和skipedlist。

跳表是一种随机化的数据结构，通过对增加层数的索引指针，来实现快速的对于链表的查找，删除，增加等操作，时间复杂度O(logN)

**redis对于跳表的优化在于：第一层是一个双向链表而不是单向链表。**方便逆向倒排排序。还有就是score允许重复，所以说基本要比较score和member

注意：redis中的skipedlist是允许相同的key存在的，因为在skipedlist中的key为分数，相同的分数会按照member的字段数来排序。

## 43.MySQL的分层架构与故障恢复过程

server层->存储引擎层->物理层

**count：`count(*)和count(id)的区别：*会统计所有行数，id只统计列不为NULL的行数`**

redo log的二阶段提交。开始，如果缓存没有就去磁盘查询，写undolog 执行语句，prepare 写redo log ，写undo log，commit redo log

redo log固定提交（刷盘策略）

原因：防止修改丢失，如果先写redo log ，再写binlog，那么如果redolog之后死了，就会存在binlog丢失的问题。

如果先写binlog 再写redo log，如果写binlog之后崩溃，这个时候系统恢复使用的是redo log，但是redo log中并没有这一条，所以说binlog就会多一个数据（上一次事务还没提交呢）



**状态恢复：**

**所以说如果是bin log 有，redo 是prepare状态，直接提交事务即可。**

**如果bin log无，redo log prepare状态，直接回滚事务。（此时只有prepare的事务，binlog中没有记录，还没来得及写入binlog，或者说只写了一半）**

**如果是binlog 有，redo commit，那么证明事务已经提交。**

（因为只有redo log才会记录得到还没有提交的事务，因为binlog存的是全局的数据库的改动，而redo log存的是单次改动）

1. **对于未prepare的事务，直接回滚即可。**
2. **根据redo log中的prepare的事务id，如果说binlog中存在该记录（事务id记录），则可以读取出来，然后在innodb中提交。**
3. **如果说binlog不存在，则直接回滚该事务（因为我只知道这个地方被修改成什么了，不知道执行的具体逻辑）**
4. **如果是commit，那么直接提交即可。**

注意：在binlog故障恢复之后，要将最后一个未提交事务提交或者回滚之后，将之后的内容全部清空。

binlog刷盘策略：（写进binlog cache）

1. sync_binlog = 0时， 表示每次提交事务都只 write，不 fsync；
2. sync_binlog = 1时， 表示每次提交事务都会执行write和 fsync；
3. sync_binlog = N时，表示每次提交事务都 write，但累积 N 个事务后才 fsync。



server层

1. 连接器：主要负责管理连接和权限认证，比如说你的账号密码，然后权限。
2. 查询缓存：缓存是否有该语句的查询。但是大多数情况不建议使用查询缓存，因为缓存可能会过期的很快，只适合做静态表或者不经常更新的表。
3. 分析器：分析SQL语句词法分析，是否有语法错误。
4. 优化器：这一阶段会根据分析器的结果来对你的查询过程做一个优化，例如说走不走索引，又好比你的联合索引是（a,b,c），但是你的语句是（a，c，b）这个时候会做一个优化，让你命中索引。
5. 执行器：权限判断，**你是否能够进行这种操作，然后就会交给存储引擎。**

存储引擎层：

​		redo log,log buffer, 缓冲池（change buffer，LRU，做了分代，防止预读失败和缓冲池污染）。

## 44.如何解决DOS攻击（SYN攻击）

SYN攻击是利用了TCP连接的第一次握手，也就是说，黑客只用去不停的发送SYN第一次握手报文，不用去回复服务器的ACK，这样服务器就会在syntimewait不停的发送ACK报文，就很浪费资源。

第一个，减少syn超时等待器的时常，如果一定时间没有接收到第三次报文，那么就直接关闭资源

第二个，SYNCookie，就是计算一个syn请求的seq的一个cookie值，将该cookie值作为syn，ack的seq号，如果说下次的ack是seq+1，那么就分配资源，建立连接。

## 45.Springboot处理请求流程

请求会打到dispatchservlet上，然后会调用dispatchservlet的doservice方法，这个方法里面主要就是调用dodispatch方法和添加request的attribute属性。然后就是通过HandlerMapping对象去获取URL对应的一个HandlerExecutionChain对象。

然后就是通过该hander的HandlerMethod方法，这个方法其实就是说通过ServletInvocableHandlerMethod中实现的，这个其实就是说对于返回值和参数的一个解析，里面有个composite对象，其中有一个list和map，分别用来存可以提供解析的解析器，以及曾经匹配过的解析器的缓存。在获取解析器的过程中，首先会去map里面找，如果说该参数类型没有被解析过

## 46.Happen-Before原则





## 48.进程控制块

1. **进程标识符，进程状态，进程优先级**
2. **资源分配清单：虚拟内存地址空间信息，文件操作符表，IO设备信息等**
3. **CPU相关信息：进程切换时，CPU的寄存器的值都被保存在PCB中，以便CPU重新执行该进程能够从断点处继续执行。**

## 49.三种线程的实现

1. 用户线程
   1. 用户空间实现的线程，不需要内核参与管理
   2. 由于不受操作系统管理，该线程发起系统调用而阻塞的时候，其他线程无法工作。
2. 内核线程
   1. 由操作系统进行管理调度，一般是由操作系统实现创建内核线程级，数量有限。
   2. 每个内核线程视为一个内核的分身，可以接收用户请求执行对应的操作
3. 轻量级线程LWP
   1. 内核线程和用户线程通信的方式，每个内核线程都一对一一个LWP，相当于是用户线程和内核线程的沟通的桥梁。

## 50.MySQL的Count()的处理

对于MyIsam而言，数据库表中会存一个count，当我们统计的时候直接以o1返回。

而对于Innodb而言，当我们每次count*都会去遍历一遍，可能会聚簇索引，也可能是非聚簇索引（因为非聚簇索引每个叶子节点短，每一页就能存储更多行）聚簇索引会有一个唯一标识的id，可能是主键，或者你建立的一个唯一索引，或者是自动生成row_id

而MyISAM可以没有主键，因为其索引上存储的是行的地址，主键的标识性不大。

## 51.Redis造成阻塞的原因

1. **在redis4.0之后，大key删除被子线程去处理，4.0之前，可能会存在大key释放的阻塞**。
2. keys * 命令，可以用scan命令替代
3. **AOF，刷盘策略为每次写入刷盘，写操作多了也会造成阻塞**。
4. **很多key过期，导致定时删除执行很多次，惰性删除和定时删除都会**。

## 52.MySQL的唯一索引和普通索引的区别

**唯一索引需要保证值唯一，所以会先确认数据是否存在，但是普通索引就无所谓了。读的时候就是如果扫描到一个值就直接返回（唯一索引）而普通索引可能还要往后面找**。

## 53.虚拟内存，段页式

传统作业方式：一次性加载，内存不可替换。

局部性原理：时间局部性和空间局部性。

页的交换技术。

实际上就是使用外存空间来扩展内存空间，当进程所需要的内存页块

## 54.如何保证缓存和数据库的一致性

1. 删除缓存，更新，再次删除缓存。
   1. 缓存变动大，可能读的频率没有那么高
2. 基于JVM内部队列的串行执行方式（将写请求和读请求都放入到一个队列，例如写请求就是一个删除缓存，写的操作，读请求就是读操作+更新缓存的操作，慢慢执行）有一个优化点就是：如果有太多的更新缓存的操作，就没有意义，只用进去一个更新缓存。
   1. 存在问题：队列太长，执行效率低
   2. 可以将不同的行的更新和读取路由到不同的jar包中，不用所有的请求都堆在一起
   3. 热点数据的更新和删除。
3. 基于可过期的key
4. 消息队列解耦
5. 监听binlog日志，阿里的canal。

## 55.限流算法

### 计数器限流

若干时间内计数器限流，到时间之后清零。

### 滑动窗口限流

通过划分时间段，将10s变成1s，但是问题就是不能够细分。（增加存储成本）

### 漏桶限流

不能处理突发请求，在同一时间如果大量请求到来，那么就算服务器没有负载，可能也要等待一会。

### 令牌桶限流

本质上是服务器不停的往一个桶里面加令牌，理论上来说最大的令牌是最大的并发数，可以比较平滑的处理请求。



处理突然的并发量：限流，预热（比如说令牌桶我可以先减少令牌放的速度，然后慢慢的恢复正常）

## 56.负载均衡算法

轮询，随机，加权轮询，重试轮询，最小连接数，iphash，过滤最小连接数。

## 57.如何处理高性能场景

高性能，高可用，高并发

高性能：体现出系统的并行处理能力，在有限的硬件条件的支持上，你的响应时间要快

高可用：表示系统的正常服务时间，就是一年都不故障，不停机，不可用的时间少

高扩展：表现出你的系统扩展能力，**流量高峰的时候能否快速完成扩容，更加平稳的削峰**。



比如说：扩展能力：**集群横向扩展，集群容灾保证可用性，高性能就得使用缓存**。

衡量指标：QPS

docker容器是可以运行你的应用的最小的一个操作系统，docker容器的新增和使用就可以很好的扩展集群，在大促销结束之后就可以回收，这就是扩展。

总的来说

纵向扩展：通过增加CPU，增加缓存，来让你的单机服务更加块

横向扩展：集群

## 57.如何处理高性能场景

缓存，降级，限流，集群

缓存的目的主要是提高系统的访问速度，以增加单位时间内系统能够处理的请求数目，还能减少对数据库的访问。

服务降级的话就是当服务出了问题，或者是说影响到了核心的功能的时候，我们就要将服务做一个降级，等到高峰过去我们在将其打开：例如说抖音商城做活动，热卖季，秒杀的时候，我们可以将查看历史订单的服务，写评论的服务降级，将更多的资源用于核心业务。

有些场景并不能使用缓存和服务降级来解决，例如说：一些稀缺资源的访问或者说频繁的复杂查询，或者是说能够同时支持的

限流：对于一段时间内的访问数进行限速。

集群：增加服务器对请求的访问，分担读请求，增加容错性。

限流又分为：

接入口限流，应用级限流和分布式限流

分布式限流就在于将限流过程原子化，就是说你得做成一个原子性的操作（比如redis+lua脚本）

因为lua脚本包含所有操作，相当于一个原子性操作，而且redis又是一个单线程处理请求的数据库，所以说用来做分布式限流再好不过了。（因为lua脚本执行的时候redis不能执行其他命令，相当于是lua脚本执行只用执行一个命令，而对于事务而言，就是集中在一起执行）

你不可能说，传到需要调用的服务，让别人服务去把你限流，这样增大了系统的开销，并且做了一些无意义的操作，并且可能会造成下游服务没办法使用，并发量高，占带宽。

## 58.Redis的RDB和AOF

RDB，通过fork一个子进程，来对当前时间节点的内存进行快照，这个快照也就是当前redis系统的一个数据的内容备份。所以RDB就适合大规模的数据恢复。

可能会丢失部分时间的修改。

触发RDB的方式：

1. 被动触发：flushall，shutdown(客户端执行)，满足条件sava条件，主从复制。
2. 手动触发：save命令（主线程执行rdb备份操作），bgsave（fork子进程触发）。

**SAVA，BGSAVE,BGREWRITEAOF不能同时执行。**

适合容灾恢复，fork子线程去持久化，不用自己去执行save。



AOF，将所有的命令记录（修改的命令）记录在aof缓冲区里面，然后根据你配置的刷盘规则定期去记录进文件。

以日志的形式来记录每个写操作。

你aof文件过大，上一次的两倍以及超过64m，就会触发bgrewiteaof ，也是**fork子进程去重写一次aof文件**。

调用AOF重写函数 （子进程）期间，会读取数据库键值对的情况，不读取aof文件，主进程会将数据记录在aof重写缓冲区里面以及现有AOF文件。

为什么存两份：防止重写失败，不干扰原来的aof文件，因为原来的aof缓存可能被占满刷盘了。

当子进程执行完重写操作之后，就会告诉主线程重写完毕。

主线程就会将重写缓冲区里面的内容写入aof，然后将这个aof文件替换掉原来的aof文件。（阻塞）



Aof刷盘策略：本质上其实还是AOF执行程序中write和sava的命令。（主线程执行write，子线程执行save的只有每秒输盘）

不保存，每秒一次，每次提交保存：

1. 在不保存的情况下：会跳过sava指令，只有三种情况会执行sava（shutdown，aof被关闭，缓存满了），这些sava都会阻塞主进程。
2. 每秒一次的话就是原则上每秒刷盘一次，但是会根据实际情况的不同而不同（一般情况下不超过2s的数据）
   1. 子进程正在执行sava命令
      1. 上一次执行sava未超过两秒，那么程序就直接返回，不执行write和sava
      2. 已经超过两秒。那么就执行write，不执行save
   2. 子进程没有执行sava
      1. 上次未超过1s，只write，不sava
      2. 超过1s，执行write和sava
3. 每次保存提交就是，每次都是由主进程执行，write和sava（最多丢失一个命令）



## 59.集群的作用

数据冗余（用来存储，备份文件），故障恢复（从机切换为主机，保障高可用），负载均衡（读命令）



## 60.分布式事务

刚性事务：2PC，3PC



柔性事务：本地消息表，消息队列事务，基于补偿的事务TCC（try，confirm，cancel）

半消息，并且执行本地事务，执行成功之后，或者不成功，会给消息队列的broker发送一个commit和回滚命令，并且消息队列broker会定期轮询事务是否执行完成，如果执行成功或者不成功，则会将半消息发送或者丢弃。

```java
/**
 * 2pc: 第一阶段去询问每个服务，锁定对应的资源，并且如果可以就返回OK，然后当所有参与者都返回OK，即可进入第二阶段，或者说有参与者不OK,第二阶段就会回滚（失败就不停的重试）。
 * 然后这是一种强一致性分布式事务，保证了所有事务要么做，要么全都不做。
 * 但是这种情况就有一定的问题，在2pc中只有第一阶段协调者有超时机制，参与者是全程没有的，也就是说只要协调者异常，那么所有的参与者都会锁住资源，无法是释放，这样就造成了极大的资源浪费。
 * 并且极端情况下可能会造成数据的不一致性。
 * 例如协调者发送完commit，某个参与者收到了并且执行，这个时候协调者和参与者都挂了，那么这个时候新协调者来的时候就不知道这个挂了的ok不 ok，可能上一个协调者做的rollback，但是不管这个时候新的协调者做什么操作，都挽回不了局面
 * 这个问题就是只有协调者知道所有参与者的状态，其他参与者是不知道的
 * 只能说通过记录一定的日志来解决。
 *
 * 问题：
 * 1.长期锁资源
 * 2.只有协调者知道所有参与者的状态
 *
 *3pc：将第一阶段准备阶段分为两步，准备和预提交阶段：准备阶段，就是去询问你是否可以执行，去获取数据库的锁，如果都ok就进入预准备阶段，这个时候其实就是对所有参与者同步一个状态。
 * 然后预提交阶段，这里的话就是协调者和参与者都引入了超时机制（这个就是把该做的都做了，和2pc的第一阶段一样）
 *
 * 3pc的话主要解决单点故障的问题，并且不阻塞资源，只是去获取数据库的锁，但是这也不能解决数据不一致的问题，因为引入了超时机制，在参与者没有及时收到协调者发送的消息的时候，会直接commit，但是这个时候如果
 * 并且预提交阶段只是给了协调者该怎么做，这么做也不一定对。
 *
 *
 * 消息队列事务消息：rocketmq以及activemq，首先发送半消息，执行本地事务，执行成功，就会去回馈，然后这个消息队列也会有定时回问机制，然后就会执行对应的操作。
 *
 * 本地消息表
 *
 * 创建订单的时候，调用管理现金模块（保证用户有足够的钱），这个时候如果RPC成功，那么就提交订单库的事务，但是这个时候如果回滚了，那么就要做一定的补偿，比如把钱退给别人。
 *
 * TCC:（预留，提交，和取消，都需要支持幂等性，和本地消息表）
 * 事务管理者：负责去confirm和cancel。相当于根据你协调者返回给我的命令报告，提供一种补偿机制，是一个基于业务层面的分布式事务解决方案
 * 但是对业务入侵性强，confirm和cancel有一个日志记录，如果说执行失败会去定时重复执行，相当于一个业务的补偿操作。
 * TCC方案严重依赖回滚和补偿代码，最终的结果是：回滚代码逻辑复杂，业务代码很难维护。
 *
 */
```

## 61.Ngnix的负载均衡算法

轮询法，随机法，iphash，最小连接数，权重轮询。

负载均衡的调用状态：down 不参与，backup：预备留，max_fails：允许失败的最大次数，fali_timeout：请求失败超时时间，就是说超过这个时间就是请求状态超时。

## 62.Exception和Error

Exception和Error都是基于Throwable的子类，区别在于Error是在正常开发情况下不太会发生的一个错误，Exception是我们在日常开发中可能会出现的错误：比如说RuntimeException，经常碰到的NullPointerException

Exception又分为不检查Exception和检查Exception，编译期的异常和运行时的异常，可能会被捕捉，抛给上级或者自己处理，从崩溃中恢复。

Error大多数情况下都会使程序处于无法运行的状态。

## 63.聚簇索引和非聚簇索引（innodb一页默认是16K）

评价一个数据结构能否作为索引的数据结构的指标就是查找过程中IO的次数。

B-Tree中一次检索**最多需要h-1次I/O**（根节点常驻内存），渐进复杂度为O(h)=O(logdN)。一般实际应用中，出度d是非常大的数字，**通常超过100，因此h非常小**（通常不超过3）。

**聚簇索引的叶子节点对应的页里面的数据是具体的行，而非聚簇索引的叶子节点里面的数据是在磁盘的地址，他需要再次访问一次磁盘才能找到对应的行地址。**

最好不要使用UUID来做主键，因为这样很可能导致innodb，B+树索引叶子节点的分裂和迁移。

**注意非聚簇索引的辅助索引也是存的表空间对应行的指针，所以说也是直接访问指针所对应的地址。**

**而聚簇索引的好处就是：叶子节点里面存的就是具体的行信息，你就不用去表空间去找了。**

**在聚簇辅助索引中只存行指针的好处：加快辅助索引项的查找，同样的页面大小一次性可以加入更多的行数据。**

**为什么辅助索引不使用地址值：避免因为行数据的地址值变化，而产生辅助索引的迁移移动过导致的节点的地址值的大规模修改。**

不过如果说存在大规模的全表扫描，还是myisam占优。

**为什么建议主键使用递增的：因为非递增可能会导致大规模的节点的移动，因为会频繁的去在中间插入行数据（保证聚簇索引因主键而有序），为什么不适用UUID：因为辅助索引存的值是主键id，主键id太长，可能导致一页装的数据太少，这样就加大了索引文件的规模。**而且如果随机写入可能会对很多页进行修改，从而无法高效率的去缓存页。

自动生成的row_id 最好不要，因为这个不能被查询到也不能被访问到，白白占了一个空间。

## 64.FutureTask

任务转换

**new->completing->normal**

**new->completing->exception**

**new->cancel**

**new->interpting->interpted**

FutureTask

里面是有一个waitnode单链表存在。

先入一个队列，然后再阻塞。如果你是一个定时的任务，就是调用的get(times)，那么就会调用LockSupport的partNanos，然后再等待事件之后如果还没有完成，那么就抛出TimeOutException。

## 65.ThreadLocal

Get会去获取map，如果map不存在，则去调用，如果不为空，那么就去获取entry。

扩容：清理旧指针，如果清理就指针之后还是大于3/4，那么久扩容，然后rehash。

## 66.Docker如何实现进程隔离

Linux的Namespace实现进程隔离。

1. Mount（filesystem）
2. User（UID/GID）
3. Network（）
4. PID（）
5. IPC（）
6. UTS（hostname隔离机制，通过设置一个单独的）

 

## 67.Java Reture之后会发生的事

1. 恢复上层方法的局部变量表和操作数栈
2. 将返回值压入调用者的操作数栈
3. 调整程序计数器的指针，指向下一个命令。



## 68.Redis的过期淘汰策略

会将ttl的键放入一个特定的字典中，定期淘汰：从字典里定期的去删除，采取的是一种随机的策略，每100ms去取20个，然后遍历判断是否过期，如果过期则删除，如果超过1/4，那么就重新去取。

惰性删除：访问的时候如果过期就删除。

redis的内存淘汰：

**lru：引入了一个时间戳的机制（24bit），然后随机采样出5个key，再淘汰掉最旧的key**

**lfu：每个key都有个计数器，会随着时间的推移而逐渐降低，对于新生代的key，会引入一个初始值的key（24bit，分为两部分：16bit的时间戳和8bit的计数器）**

## 69.MySQL的update锁：临键锁（Next-Key锁） 待解决

注意，在唯一索引中如果使用临建锁如果能够对应到具体的值，就会降级为记录锁，否则就会降级为间隙锁。

如果是范围条件，就是一个临键锁的上开下闭合区间

幻读在MVCC的情况下是被快照读解决，但是不能解决写时读，在写时读的情况下，就会产生幻读。

select for update：相当于update锁：**为了避免自己看到的数据并不是数据库存储的最新数据并且看到的数据只能由自己修改**，这种主要就是加一个X锁了，并且是Next-key lock

对于意向锁的话，就是说select lock in share mode;

## 69.MySQL的锁机制

### update的锁

注意：**select for update相当于update 锁**，update，insert，delete都是添加一个排他锁。

update的流程：MySQL Server层根据where条件，从Innodb读取第一个满足条件的记录，然后将第一条记录返回并且加锁，更新完成之后，再去取下一条记录，直到没有满足条件的记录为止。

### insert锁

### 意向锁

意向锁主要是用于判断能不能对该表添加表锁的，因为如果我们要去添加表锁，那么其实就是要么去判断

1. 是否已经被别的事务锁表
2. 是否有行被锁了（不管是读锁还是写锁）

那么这个时候判断条件2而言，一次次遍历未免太过于麻烦，所以就存在意向锁，当事务想要给某个行加锁，就得去申请**意向共享锁**，然后再去添加行锁（共享锁）。这个时候如果我们想去获取整个表的表锁，就回去检测意向共享锁，如果存在意向共享锁，那么就获取表锁失败。

意向锁不会和行锁冲突，只会和表锁冲突，因为意向锁就是为了让锁全表的时候知道了某个行被加了锁。

意向锁和意向锁之间是相互兼容，意向共享锁和共享锁兼容，意向排他锁和排他锁以及共享锁都不兼容。

### 幻读

争对于insert操作，指在一次事务中，对于事务A执行的当前读（update，insert，delete，for update，lock in share mode）的操作会被在事务A之后执行的事务B在插入操作并且提交事务之后影响。（只会发生在写时读，像update，insert都会去找最新的值，不会执行快照值）。真正解决幻读的是临键锁！！！

事务A：

![image-20220304215853469](C:\Users\更科瑠夏\AppData\Roaming\Typora\typora-user-images\image-20220304215853469.png)

事务B：

![image-20220304215902339](C:\Users\更科瑠夏\AppData\Roaming\Typora\typora-user-images\image-20220304215902339.png)



表锁：lock tables 表名 read/write  解锁：unlock tables

行锁：for update，lock in share mode。



## 70.Redis的事务、lua脚本区别

redis的事务都可以保证一致性和隔离性，但是不能保持原子性。



redis的事务相当于将每个指令存在事务缓存队列中，但是每个命令都需要进行一次网络读写，但是执行事务的过程中不能执行别的命令。（可以配合乐观锁）。



redis的lua脚本相当于是一个命令，只需要一次网络读取。（我们可以通过lua脚本来自定义逻辑，比如说可以获取上一个命令的中间返回结果，因为会占用主线程，所以不适合做一些太耗时的操作）。



pipeline也是一次网络读取，但是不能保证一致性，因为此时别的命令也可以执行。（会将执行结果放入缓存，最后在统一返回，管道可以一次性去读取多个命令，减少网络IO的次数，避免了一定的上下文切换）

注意：pipeline可以保证对同一个客户端的执行的命令是有序的，但是对于多个客户端执行的过程就不一定了。（可能两个客户端的pipeline交替执行）



注意：**redis分布式锁，如果说在master加锁后宕机，此时其数据还没有同步到别的从机，这个时候发生了集群容灾恢复，原来的从机升级为了主机，那么就会两个客户端都能拿到锁。**

## 71.如何解决Redis分布式锁的问题

如果对一致性要求强，可以使用zookeeper来进行分布式锁的控制。就是说redis的分布式锁是存在一个master宕机情况下，双端获取到分布式锁的问题。

Zookeeper的话是一个CP的集群，但是其实他并不是一个强一致性，根据ZAB协议，其提交事务的消息广播是集群一半以上的节点写入成功，则返回，所以其实在读请求的情况下并不能保证所有节点的一致性问题。

